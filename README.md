<a href="https://www.codecogs.com/eqnedit.php?latex=\fn_jvn&space;\huge&space;\theta&space;\text{-space&space;Adversarial&space;Attacks}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\fn_jvn&space;\huge&space;\theta&space;\text{-space&space;Adversarial&space;Attacks}" title="\huge \theta \text{-space Adversarial Attacks}" /></a>

From the given model parameters ![formula](https://render.githubusercontent.com/render/math?math=\theta), find parameters ![formula](https://render.githubusercontent.com/render/math?math=\theta^*) such that adversaries generated from ![formula](https://render.githubusercontent.com/render/math?math=\theta^*) are stronger than adversaries generated from ![formula](https://render.githubusercontent.com/render/math?math=\theta).

The repo contains target and substitute models. To evaluate a particular training method, run `eval_{training_method_name}.py` file.

## Requirements
```
advertorch
torch
python3
```
