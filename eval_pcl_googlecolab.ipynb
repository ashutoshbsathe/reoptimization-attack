{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reoptimization_pcl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONfdRlTZteJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install advertorch > /dev/null\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable \n",
        "from advertorch.attacks import GradientSignAttack, LinfBasicIterativeAttack\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2sEpIYXtt3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys \n",
        "import torchvision.datasets as datasets \n",
        "import torchvision.transforms as transforms \n",
        "from torch.utils.data.sampler import SubsetRandomSampler as SRS \n",
        "import torch.utils.data as data_utils \n",
        "import numpy as np \n",
        "CIFAR10_DATA_ROOT = './cifar10_data/'\n",
        "SEED = 161803398 # Golden Ratio\n",
        "def get_cifar10_data_loaders(batch_size=64, n_train=40000, \\\n",
        "    n_val=10000, n_test=10000, train_transform=None, \\\n",
        "    val_transform=None, test_transform=None):\n",
        "\n",
        "    assert n_train + n_val == 50000\n",
        "    if train_transform is None:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(size=32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "        ])\n",
        "    if val_transform is None:\n",
        "        val_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "        ])\n",
        "    if test_transform is None:\n",
        "        test_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "        ])\n",
        "    \n",
        "    train_set = datasets.CIFAR10(root=CIFAR10_DATA_ROOT, download=True, \\\n",
        "        train=True, transform=train_transform)\n",
        "    val_set = datasets.CIFAR10(root=CIFAR10_DATA_ROOT, download=True, \\\n",
        "        train=True, transform=val_transform)\n",
        "    test_set = datasets.CIFAR10(root=CIFAR10_DATA_ROOT, download=True, \\\n",
        "        train=False, transform=test_transform)\n",
        "\n",
        "    indices = np.arange(0, 50000)\n",
        "    np.random.seed(SEED)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_sampler = SRS(indices[:n_train])\n",
        "    val_sampler = SRS(indices[n_train:])\n",
        "    test_sampler = SRS(np.arange(0, 10000))\n",
        "\n",
        "    train_loader = data_utils.DataLoader(train_set, batch_size=batch_size, \\\n",
        "        sampler=train_sampler)\n",
        "    val_loader = data_utils.DataLoader(val_set, batch_size=batch_size, \\\n",
        "        sampler=val_sampler)\n",
        "    test_loader = data_utils.DataLoader(test_set, batch_size=batch_size, \\\n",
        "        sampler=test_sampler)\n",
        "    \n",
        "    return train_loader, val_loader, test_loader \n",
        "\n",
        "def progress(curr, total, suffix='', bar_len=48):\n",
        "    filled = int(round(bar_len * curr / float(total))) if curr != 0 else 1\n",
        "    bar = '=' * (filled - 1) + '>' + '-' * (bar_len - filled)\n",
        "    sys.stdout.write('\\r[%s](%d/%d) .. %s' % (bar, curr, total, suffix))\n",
        "    sys.stdout.flush()\n",
        "    if curr == total:\n",
        "        bar = bar_len * '='\n",
        "        sys.stdout.write('\\r[%s](%d/%d) .. %s .. Completed\\n' % (bar, curr, total, suffix))\n",
        "    return \n",
        "\n",
        "def _preprocess_state_dict(state_dict):\n",
        "    from collections import OrderedDict\n",
        "    new_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        if not k.endswith('num_batches_tracked'):\n",
        "            if k.startswith('module.'):\n",
        "                new_dict[k[7:]] = v\n",
        "            else:\n",
        "                new_dict[k] = v\n",
        "    return new_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSnC-61-uG7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d6c4cebe-71b7-462b-d9e3-a0e7a2437887"
      },
      "source": [
        "!wget https://github.com/aamir-mustafa/pcl-adversarial-defense/raw/master/robust_model.pth.tar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-31 13:17:49--  https://github.com/aamir-mustafa/pcl-adversarial-defense/raw/master/robust_model.pth.tar\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/aamir-mustafa/pcl-adversarial-defense/master/robust_model.pth.tar [following]\n",
            "--2020-01-31 13:17:49--  https://raw.githubusercontent.com/aamir-mustafa/pcl-adversarial-defense/master/robust_model.pth.tar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16162240 (15M) [application/octet-stream]\n",
            "Saving to: ‘robust_model.pth.tar.1’\n",
            "\n",
            "\rrobust_model.pth.ta   0%[                    ]       0  --.-KB/s               \rrobust_model.pth.ta 100%[===================>]  15.41M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-01-31 13:17:50 (199 MB/s) - ‘robust_model.pth.tar.1’ saved [16162240/16162240]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ossfi64uN_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fc32036-f45e-40e9-e1d9-674b58a8310d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo6z37F9u3Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kanged from https://raw.githubusercontent.com/aamir-mustafa/pcl-adversarial-defense/master/resnet_model.py\n",
        "\"\"\"\n",
        "Created on Tue Apr  2 14:21:30 2019\n",
        "\n",
        "@author: aamir-mustafa\n",
        "\"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):  # (conv-bn-relu) x 3 times\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual   # in our case is none\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, depth, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        # Model type specifies number of layers for CIFAR-10 model\n",
        "        assert (depth - 2) % 6 == 0, 'depth should be 6n+2'\n",
        "        n = (depth - 2) // 6\n",
        "\n",
        "        block = Bottleneck if depth >=44 else BasicBlock\n",
        "\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, n)\n",
        "        \n",
        "        self.layer2 = self._make_layer(block, 32, n, stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, n, stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(8)\n",
        "        \n",
        "        self.maxpool2= nn.MaxPool2d(16)\n",
        "        self.fc = nn.Linear(64 * block.expansion, 1024)\n",
        "        self.fcf = nn.Linear(1024,num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        \n",
        "\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)   \n",
        "\n",
        "        x = self.layer1(x)  \n",
        "        x = self.layer2(x)  \n",
        "        \n",
        "        m =  self.maxpool2(x) \n",
        "        m = m.view(m.size(0), -1) # 128 dimensional\n",
        "        \n",
        "        x = self.layer3(x)  \n",
        "\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        z = x.view(x.size(0), -1) # 256 dimensional\n",
        "        x = self.fc(z)            # 1024 dimensional\n",
        "        y = self.fcf(x)           # num_classes dimensional\n",
        "        \n",
        "        return y # m, z, x, y - original return values\n",
        "\n",
        "\n",
        "def resnet(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a ResNet model.\n",
        "    \"\"\"\n",
        "    return ResNet(**kwargs)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbuuNesDuiqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "05f1e4f4-e791-4ed7-80c2-ebef48b8514f"
      },
      "source": [
        "model = resnet(num_classes=10, depth=110).cuda()\n",
        "model.load_state_dict(_preprocess_state_dict(torch.load('./robust_model.pth.tar')['state_dict']))\n",
        "model.eval()\n",
        "\n",
        "sub = resnet(num_classes=10, depth=110).cuda()\n",
        "sub.load_state_dict(_preprocess_state_dict(torch.load('/content/drive/My Drive/reoptimization_attack/cifar_pcl_defense/best_substitute_model_cifar_pcl_defense.pt')))\n",
        "sub.eval()\n",
        "\n",
        "adversaries = [\n",
        "    GradientSignAttack(model, nn.CrossEntropyLoss(size_average=False), eps=float(8.0/255)),\n",
        "    GradientSignAttack(sub, nn.CrossEntropyLoss(size_average=False), eps=float(8.0/255)),\n",
        "]\n",
        "_, _, test_loader = get_cifar10_data_loaders()\n",
        "for adversary in adversaries:\n",
        "    correct_adv = 0\n",
        "    for i, (x_batch, y_batch) in enumerate(test_loader):\n",
        "        x_batch, y_batch = x_batch.cuda(), y_batch.cuda()\n",
        "        adv_x_batch = adversary.perturb(x_batch, y_batch)\n",
        "        logits = model(adv_x_batch)\n",
        "        _, preds = torch.max(logits, 1)\n",
        "        correct_adv += (preds == y_batch).sum().item()\n",
        "        progress(i+1, len(test_loader), 'correct_adv = {}'.format(correct_adv))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[================================================](157/157) .. correct_adv = 5842 .. Completed\n",
            "[================================================](157/157) .. correct_adv = 5761 .. Completed\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}